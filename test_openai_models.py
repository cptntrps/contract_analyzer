#!/usr/bin/env python3
"""
Test script for OpenAI model selection functionality
Demonstrates how to use the new model selection features
"""

import sys
import os
from typing import Dict, Any

# Add the project root to the Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from llm_providers import OpenAIProvider
from config import config

def test_model_selection():
    """Test the OpenAI model selection functionality"""
    
    print("üîß Testing OpenAI Model Selection")
    print("=" * 50)
    
    # Check if API key is available
    if not config.OPENAI_API_KEY:
        print("‚ùå OPENAI_API_KEY not found in environment")
        print("Please set your API key in .env file")
        return False
    
    try:
        # Initialize OpenAI provider
        provider_config = {
            'api_key': config.OPENAI_API_KEY,
            'model': config.OPENAI_MODEL,
            'timeout': config.OPENAI_TIMEOUT,
            'temperature': config.LLM_TEMPERATURE,
            'max_tokens': config.LLM_MAX_TOKENS
        }
        
        provider = OpenAIProvider(provider_config)
        print(f"‚úÖ OpenAI Provider initialized with model: {provider.get_current_model()}")
        
        # Test available models
        print("\nüìã Available Models:")
        print("-" * 30)
        models = provider.get_available_models()
        
        for model in models:
            status = "‚≠ê CURRENT" if model['current'] else "‚úÖ RECOMMENDED" if model['recommended'] else "  "
            print(f"{status} {model['name']}")
            print(f"     {model['description']}")
            print(f"     Context: {model['context_window']:,} tokens | Tier: {model['tier']}")
            print()
        
        # Test recommendations
        print("\nüéØ Model Recommendations:")
        print("-" * 30)
        recommendations = provider.get_model_recommendations()
        
        for category, models in recommendations.items():
            print(f"‚Ä¢ {category.title()}: {', '.join(models)}")
        
        # Test model info
        print("\nüîç Model Details:")
        print("-" * 30)
        current_model = provider.get_current_model()
        model_info = provider.get_model_info(current_model)
        
        if model_info:
            print(f"Current Model: {current_model}")
            print(f"Description: {model_info['description']}")
            print(f"Context Window: {model_info['context_window']:,} tokens")
            print(f"Recommended: {'Yes' if model_info['recommended'] else 'No'}")
            print(f"Tier: {model_info['tier']}")
        
        # Test model switching
        print("\nüîÑ Testing Model Switch:")
        print("-" * 30)
        
        # Try switching to gpt-3.5-turbo
        if current_model != 'gpt-3.5-turbo':
            print("Switching to gpt-3.5-turbo...")
            result = provider.change_model('gpt-3.5-turbo')
            
            if result['success']:
                print(f"‚úÖ {result['message']}")
                print(f"Previous: {result['previous_model']}")
                print(f"Current: {result['current_model']}")
                
                # Switch back
                switch_back = provider.change_model(current_model)
                if switch_back['success']:
                    print(f"‚úÖ Switched back to {current_model}")
                else:
                    print(f"‚ùå Failed to switch back: {switch_back['message']}")
            else:
                print(f"‚ùå Model switch failed: {result['message']}")
        
        # Test invalid model
        print("\n‚ùå Testing Invalid Model:")
        print("-" * 30)
        invalid_result = provider.change_model('invalid-model')
        print(f"Expected failure: {invalid_result['message']}")
        
        print("\nüéâ All tests completed successfully!")
        return True
        
    except Exception as e:
        print(f"‚ùå Error during testing: {e}")
        return False

def print_model_selection_guide():
    """Print a guide for choosing the right OpenAI model"""
    
    print("\nüìñ OpenAI Model Selection Guide")
    print("=" * 50)
    
    print("ü•á **RECOMMENDED MODELS**")
    print("‚Ä¢ gpt-4o - Best overall choice (fast, cheap, high quality)")
    print("‚Ä¢ gpt-4-turbo - Good balance of performance and cost")
    print("‚Ä¢ gpt-3.5-turbo - Budget-friendly option")
    
    print("\nüí∞ **COST CONSIDERATIONS**")
    print("‚Ä¢ Cheapest: gpt-3.5-turbo ‚Üí gpt-4o ‚Üí gpt-4-turbo ‚Üí gpt-4")
    print("‚Ä¢ Most expensive: gpt-4 (mostly deprecated)")
    
    print("\n‚ö° **PERFORMANCE**")
    print("‚Ä¢ Fastest: gpt-4o ‚Üí gpt-3.5-turbo ‚Üí gpt-4-turbo ‚Üí gpt-4")
    print("‚Ä¢ Highest quality: gpt-4o ‚Üí gpt-4-turbo ‚Üí gpt-4 ‚Üí gpt-3.5-turbo")
    
    print("\nüìù **CONTEXT WINDOWS**")
    print("‚Ä¢ 128k tokens: gpt-4o, gpt-4-turbo")
    print("‚Ä¢ 16k tokens: gpt-3.5-turbo, gpt-3.5-turbo-16k")
    print("‚Ä¢ 8k tokens: gpt-4 (legacy)")
    
    print("\nüéØ **USE CASE RECOMMENDATIONS**")
    print("‚Ä¢ Contract Analysis: gpt-4o (recommended)")
    print("‚Ä¢ Budget-conscious: gpt-3.5-turbo")
    print("‚Ä¢ Long documents: gpt-4o or gpt-4-turbo")
    print("‚Ä¢ High accuracy needed: gpt-4o")

if __name__ == "__main__":
    print_model_selection_guide()
    test_model_selection() 